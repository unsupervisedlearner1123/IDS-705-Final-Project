# Analysis of Malware Prediction in Windows Devices <img width=90 align="right" src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e6/Duke_University_logo.svg/1024px-Duke_University_logo.svg.png">
## Final Project for IDS 705: Principles of Machine Learning 

*Contributors: Mohammad Anas, Ying Feng, Vicky Nomwesigwa, Deekshita Saikia*

### Abstract
Malware infection rates have been on the rise in recent years. Given the data deluge the industry currently faces, it is essential to guard our devices well so that the impact from malware attacks can be minimized. Through this analysis, we explore different tree-based models that can predict a Windows machine’s probability of getting infected by malware, based on different hardware and software configurations of that machine. A LightGBM classification model performed the best in our hold-out dataset in predicting if a machine would be infected. We also delve into which features of a device are most sensitive to a malware attack, and it was found that the diagonal display size is particularly sensitive to changes in the underlying sample.

### Data
The dataset used in this analysis was collected from [Kaggle](https://www.kaggle.com/competitions/microsoft-malware-prediction), provided by Microsoft to encourage open-source progress on effective techniques for predicting malware occurrences. The goal of this competition was to predict a Windows machine’s probability of getting infected by various families of malware, based on different properties of that machine. The telemetry data containing these properties and the machine infections was generated by combining heartbeat and threat reports collected by Microsoft's endpoint protection solution, Windows Defender.

The original dataset has 16 million values and 83 features, most of which were categorical attributes. Each row in this dataset corresponds to a machine, uniquely identified by a `MachineIdentifier`. `HasDetections` is the ground truth and indicates if malware was detected on the machine. A significant limitation of this analysis was the size of the datasets, which warranted significant compute and time resources. Owing to these constraints, we extract a stratified sample of approximately 1.5 million (~17%) observations from the original dataset. The stratification was performed on `HasDetections`, `Platform`, `Processor`, `IsProtected` and `Census_IsTouchEnabled`. The raw sample file can be found at `./data/OMG_OUR_LIFE_DEPENDS_ON_THIS.csv.zip`.

### Requirements
This project is built with Python 3, and the visualizations are created using Jupyter Notebooks. The following steps can be followed to replicate the analysis:

* Clone repo with SSH key
```
git clone git@github.com:unsupervisedlearner1123/IDS-705-Final-Project.git
```

* Install all packages for analysis
```
pip install -r requirements.txt
```

* Unzip files in `./data/` and set current working directory to repo's directory.

* To replicate creating the sample used in this analysis, use code `00_Essence_of_life.ipynb` and retain the same value of `random_state`.

* To replicate the data exporatory analysis, run code `10_Data_Preprocessing+EDA.ipynb`.

* To replicate the feature selection process, run code `20_Feature_Selection.ipynb`. The outut from code `10` feeds into code `20`.

* To replicate the pre-processing steps on unseen data, use code `preprocessing_pipeline.py`.

* To replicate the hyper-paramater tuning and model training steps, use code `30_tuning_LGBM.ipynb` to fit a LightGBM classifier, `31_tuning_RF.ipynb` to fit a Random Forest classifier, and `32_tuning_XGB.ipynb` to fit an XGBoost classifier.

* To test the classifiers on unseen data with tuned hyper-parameters, use code `40_Predictions_on_Test.py`.

* To replicate the experiments, use code `50_experiments.py`.

### Environment Variables 
The script `00_Essence_of_life.ipynb` reads `train.csv` from a custom AWS S3 bucket. This requires the following environment variables to be set:
| Name | Value |
| --- | --- |
| `aws_bucket_name` | Name of the S3 Bucket to use for data storage |
| `AWS_SECRET_KEY` | Your AWS Access Key ID |
| `SECRET_ACCESS_KEY` | Your AWS Secret Access Key |

This file can also be downloaded directly from [here](https://www.kaggle.com/competitions/microsoft-malware-prediction/data?select=train.csv).

### References
1.	Bryan Dixon, Y. J. (2011). Location based power analysis to detect malicious code in smartphones. Proceedings of the 1st ACM workshop on Security and privacy in smartphones and mobile devices, SPSM, 27-32.
2.	Daniele Uccia, L. A. (2018). Survey of machine learning techniques for malware analysis. Computer Security.
3.	Ekta Gandotra, D. B. (2014). Malware analysis and classification: a survey. Journal of Information Security, 56-64.
4.	H.S. Galal, Y. M. (2016). Behavior-based features model for malware detection. J. Comput. Virol. Hacking Tech., 59-67.
5.	Hahnsang Kim, J. S. (2018). Detecting energygreedy anomalies and mobile malware variants. Proceedings of the 6th international conference on Mobile systems, applications, and services, MobiSys, 239–252.
6.	Holland, P. W. (1986). Statistics and Causal Inference. J. Am. Stat. Assoc, 945-60.
7.	I. Zelinka, E. A. (2019). An ensemble-based malware detection model using minimum feature set. Mendel, 25 (2), 1-10.
8.	Kaggle. (2022, April 06). Microsoft Malware Prediction. Retrieved from Kaggle: https://www.kaggle.com/c/microsoft-malware-prediction
9.	Lei Liu, G. Y. (2009). Virusmeter: Preventing your cellphone from spies. Proceedings of the 12th International Symposium on Recent Advances in Intrusion Detection, RAID, 244–264.
10.	Microsoft Docs. (2022, April 6). Fileless threats. Retrieved from Microsoft Docs: https://docs.microsoft.com/en-us/microsoft-365/security/intelligence/fileless-threats?view=o365-worldwide
11.	P. Burnap, R. F. (2018). Malware classification using self organising feature maps and machine activity data. Computer Security, 399-410.
12.	PurpleSec. (2021, October 28). 10 Cyber Security Trends You Can't Ignore In 2021. Retrieved from https://purplesec.us/cyber-security-trends-2021/
13.	Rubin, D. B. (1978). Bayesian Inference for Causality: The Importance of Randomization. The Annals of Statistics 6, 34-58.
14.	S. Cesare, Y. X. (2013). Control Flow-Based Malware VariantDetection. IEEE Trans. Depend. Secure Comput., 307-317.
15.	Sanjeev Das, Y. L. (2016). Semantics-Based Online Malware Detection: Towards Efficient Real-Time Protection Against Malware. IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY.
16.	W. Han, J. X. (2019). MalDAE: detecting and explaining malware based on correlation and fusion of static and dynamic characteristics. Comput. Secur., 83, 208-233.
17.	Y. Qiao, Y. Y. (2014). CBM: free, automatic malware analysis framework using API call sequences. Knowledge Engineering and Management, Springer, Berlin, 225-236.
18.	Qi, C., Qiu, L., & Diao, J. (2019). On Estimating Model in Feature Selection With Cross-Validation. IEEE. https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8610148&tag=1
