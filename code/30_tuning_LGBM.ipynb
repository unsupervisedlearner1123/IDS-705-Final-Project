{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymQCQqgiUfMB",
        "outputId": "b24efac9-4d5a-44f2-807c-2776ffac6dc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-xSnxyRXdM3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import warnings\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "from hyperopt import Trials, fmin, tpe, hp\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import loguniform\n",
        "import lightgbm as lgb\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "os.chdir(\"/add/your/path/here/\")\n",
        "# print(os.chdir(os.getenv('path_env')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Rkb7xZ4XeZr"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# Loading shortlisted feature from pickle file\n",
        "with open(\"./trained_models/imp_features.pkl\", \"rb\") as f:\n",
        "  features = pickle.load(f)\n",
        "\n",
        "shortlisted_features = list(features.keys())[:150]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyOewsVKXkMn"
      },
      "outputs": [],
      "source": [
        "# Loading train, test and validation files\n",
        "train = pd.read_csv(\"./data/train.csv\")\n",
        "train.name = \"Train\"\n",
        "val = pd.read_csv(\"./data/val.csv\")\n",
        "val.name = \"Validation\"\n",
        "test = pd.read_csv(\"./data/test.csv\")\n",
        "test.name = \"Test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fabbJ_umXs9c"
      },
      "outputs": [],
      "source": [
        "cols_to_drop = [\n",
        "    \"IsBeta\",\n",
        "    \"AutoSampleOptIn\",\n",
        "    \"SMode\",\n",
        "    \"Census_IsPortableOperatingSystem\",\n",
        "    \"OrganizationIdentifier\",\n",
        "    \"Census_InternalBatteryNumberOfCharges\",\n",
        "]\n",
        "\n",
        "\n",
        "categorical_cols = [\n",
        "    \"IsSxsPassiveMode\",\n",
        "    \"RtpStateBitfield\",\n",
        "    \"AVProductStatesIdentifier\",\n",
        "    \"AVProductsInstalled\",\n",
        "    \"AVProductsEnabled\",\n",
        "    \"HasTpm\",  # think of dropping it\n",
        "    \"CountryIdentifier\",\n",
        "    \"CityIdentifier\",\n",
        "    # \"OrganizationIdentifier\",\n",
        "    \"GeoNameIdentifier\",\n",
        "    \"LocaleEnglishNameIdentifier\",\n",
        "    \"Platform\",\n",
        "    \"Processor\",\n",
        "    \"OsVer\",  # Think of dropping it\n",
        "    \"OsBuild\",\n",
        "    \"OsSuite\",\n",
        "    \"IsProtected\",\n",
        "    \"IeVerIdentifier\",\n",
        "    \"Firewall\",\n",
        "    \"UacLuaenable\",  # THINK of dropping\n",
        "    \"Census_OEMNameIdentifier\",\n",
        "    \"Census_OEMModelIdentifier\",\n",
        "    \"Census_ProcessorManufacturerIdentifier\",\n",
        "    \"Census_ProcessorModelIdentifier\",\n",
        "    \"Census_HasOpticalDiskDrive\",\n",
        "    \"Census_PowerPlatformRoleName\",\n",
        "    \"Census_OSVersion\",\n",
        "    \"Census_OSArchitecture\",\n",
        "    \"Census_OSBranch\",  # OS version\n",
        "    \"Census_OSBuildNumber\",  # OS version\n",
        "    \"Census_OSBuildRevision\",  # OS version\n",
        "    \"Census_OSInstallLanguageIdentifier\",  # think of dropping it\n",
        "    \"Census_OSUILocaleIdentifier\",\n",
        "    \"Census_IsFlightsDisabled\",\n",
        "    \"Census_FlightRing\",\n",
        "    \"Census_FirmwareManufacturerIdentifier\",\n",
        "    \"Census_FirmwareVersionIdentifier\",\n",
        "    \"Census_IsSecureBootEnabled\",\n",
        "    \"Census_IsVirtualDevice\",\n",
        "    \"Census_IsTouchEnabled\",\n",
        "    \"Census_IsPenCapable\",\n",
        "    \"Census_IsAlwaysOnAlwaysConnectedCapable\",\n",
        "    \"Wdft_IsGamer\",\n",
        "    \"Wdft_RegionIdentifier\",\n",
        "    # \"HasDetections\",\n",
        "]\n",
        "\n",
        "nulls_cols = [\n",
        "    \"MachineIdentifier\",\n",
        "    \"ProductName\",\n",
        "    \"EngineVersion\",\n",
        "    \"AppVersion\",\n",
        "    \"AvSigVersion\",\n",
        "    \"IsBeta\",\n",
        "    \"RtpStateBitfield\",\n",
        "    \"IsSxsPassiveMode\",\n",
        "    \"AVProductStatesIdentifier\",\n",
        "    \"AVProductsInstalled\",\n",
        "    \"AVProductsEnabled\",\n",
        "    \"HasTpm\",\n",
        "    \"CountryIdentifier\",\n",
        "    \"CityIdentifier\",\n",
        "    \"OrganizationIdentifier\",\n",
        "    \"GeoNameIdentifier\",\n",
        "    \"LocaleEnglishNameIdentifier\",\n",
        "    \"Platform\",\n",
        "    \"Processor\",\n",
        "    \"OsVer\",\n",
        "    \"OsBuild\",\n",
        "    \"OsSuite\",\n",
        "    \"OsPlatformSubRelease\",\n",
        "    \"OsBuildLab\",\n",
        "    \"SkuEdition\",\n",
        "    \"IsProtected\",\n",
        "    \"AutoSampleOptIn\",\n",
        "    \"SMode\",\n",
        "    \"IeVerIdentifier\",\n",
        "    \"SmartScreen\",\n",
        "    \"Firewall\",\n",
        "    \"UacLuaenable\",\n",
        "    \"Census_MDC2FormFactor\",\n",
        "    \"Census_DeviceFamily\",\n",
        "    \"Census_OEMNameIdentifier\",\n",
        "    \"Census_OEMModelIdentifier\",\n",
        "    \"Census_ProcessorCoreCount\",\n",
        "    \"Census_ProcessorManufacturerIdentifier\",\n",
        "    \"Census_ProcessorModelIdentifier\",\n",
        "    \"Census_PrimaryDiskTotalCapacity\",\n",
        "    \"Census_PrimaryDiskTypeName\",\n",
        "    \"Census_SystemVolumeTotalCapacity\",\n",
        "    \"Census_HasOpticalDiskDrive\",\n",
        "    \"Census_TotalPhysicalRAM\",\n",
        "    \"Census_ChassisTypeName\",\n",
        "    \"Census_InternalPrimaryDiagonalDisplaySizeInInches\",\n",
        "    \"Census_InternalPrimaryDisplayResolutionHorizontal\",\n",
        "    \"Census_InternalPrimaryDisplayResolutionVertical\",\n",
        "    \"Census_PowerPlatformRoleName\",\n",
        "    \"Census_InternalBatteryNumberOfCharges\",\n",
        "    \"Census_OSVersion\",\n",
        "    \"Census_OSArchitecture\",\n",
        "    \"Census_OSBranch\",\n",
        "    \"Census_OSBuildNumber\",\n",
        "    \"Census_OSBuildRevision\",\n",
        "    \"Census_OSEdition\",\n",
        "    \"Census_OSSkuName\",\n",
        "    \"Census_OSInstallTypeName\",\n",
        "    \"Census_OSInstallLanguageIdentifier\",\n",
        "    \"Census_OSUILocaleIdentifier\",\n",
        "    \"Census_OSWUAutoUpdateOptionsName\",\n",
        "    \"Census_IsPortableOperatingSystem\",\n",
        "    \"Census_GenuineStateName\",\n",
        "    \"Census_ActivationChannel\",\n",
        "    \"Census_IsFlightsDisabled\",\n",
        "    \"Census_FlightRing\",\n",
        "    \"Census_FirmwareManufacturerIdentifier\",\n",
        "    \"Census_FirmwareVersionIdentifier\",\n",
        "    \"Census_IsSecureBootEnabled\",\n",
        "    \"Census_IsVirtualDevice\",\n",
        "    \"Census_IsTouchEnabled\",\n",
        "    \"Census_IsPenCapable\",\n",
        "    \"Census_IsAlwaysOnAlwaysConnectedCapable\",\n",
        "    \"Wdft_IsGamer\",\n",
        "    \"Wdft_RegionIdentifier\",\n",
        "    # \"HasDetections\",\n",
        "]\n",
        "\n",
        "# Features to drop post correlation checks\n",
        "corr_cols_drop = [\n",
        "    \"Census_ProcessorCoreCount\",\n",
        "    \"Census_PrimaryDiskTotalCapacity\",\n",
        "    \"Census_SystemVolumeTotalCapacity\",\n",
        "    \"Census_TotalPhysicalRAM\",\n",
        "    \"Census_InternalPrimaryDiagonalDisplaySizeInInches\",\n",
        "    \"Census_InternalPrimaryDisplayResolutionHorizontal\",\n",
        "    \"Census_InternalPrimaryDisplayResolutionVertical\",\n",
        "    \"AVProductsInstalled\",\n",
        "]\n",
        "\n",
        "log_corr_cols_to_drop = [\n",
        "    \"log_Census_PrimaryDiskTotalCapacity\",\n",
        "    \"log_Census_InternalPrimaryDisplayResolutionVertical\",\n",
        "]\n",
        "\n",
        "# Categorical columns similar to other columns\n",
        "# redundant information. Hence dropped.\n",
        "cats_to_drop = [\n",
        "    \"MachineIdentifier\",\n",
        "    \"OsBuildLab\",\n",
        "    \"CityIdentifier\",\n",
        "    \"GeoNameIdentifier\",\n",
        "    \"LocaleEnglishNameIdentifier\",\n",
        "    \"Census_ChassisTypeName\",\n",
        "    \"Census_OSVersion\",\n",
        "    \"Census_OSBranch\",\n",
        "    \"Census_OSBuildNumber\",\n",
        "    \"Census_OSSkuName\",\n",
        "    \"Wdft_RegionIdentifier\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXiPExbuX6pu"
      },
      "outputs": [],
      "source": [
        "def drop_cols(df, *args):\n",
        "    \"\"\"Drop Columns.\"\"\"\n",
        "    for x in args:\n",
        "        df.drop(columns=x, inplace=True)\n",
        "\n",
        "\n",
        "def replace_nulls(df):\n",
        "    \"\"\"Impute Missing Values with Place holders.\"\"\"\n",
        "    # Replace nulls acc to data types\n",
        "    for col in nulls_cols:\n",
        "        if df[col].dtype.name in [\"int64\", \"float64\"]:\n",
        "            df[col] = df[col].fillna(-999999999).copy()\n",
        "        else:\n",
        "            df[col].fillna(\"Missing\", inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "# df.drop(columns = cols_to_drop,inplace=True)\n",
        "\n",
        "\n",
        "def convert_num_to_cat(df):\n",
        "    \"\"\"Ensure Correct Datatypes.\"\"\"\n",
        "    # Correcting some numerical attributes to categorical\n",
        "    for col in categorical_cols:\n",
        "        df[col] = df[col].astype(\"str\").copy()\n",
        "    return df\n",
        "\n",
        "\n",
        "def median_impute(df):\n",
        "    \"\"\"Impute Missing Values with Median.\"\"\"\n",
        "    # Imputing the float attributes with the median\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype.name in [\"int64\", \"float64\"]:\n",
        "            df[col].replace(-999999999, df[col].median(), inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "def treat_outlier(df):\n",
        "    \"\"\"Outlier Treatment by placing them within 3 standard deviations of the mean.\"\"\"\n",
        "    # Pre-processing for the numerical attributes\n",
        "    # 1. Remove the outliers based on 3 standard deviations away from mean\n",
        "    for col in df.select_dtypes(include=np.number).columns.tolist():\n",
        "\n",
        "        a = np.mean(df[col])\n",
        "        b = np.std(df[col])\n",
        "\n",
        "        df[col] = np.where(\n",
        "            df[col] > a + 3 * b,\n",
        "            a + 3 * b,\n",
        "            np.where(df[col] < a - 3 * b, a - 3 * b, df[col]),\n",
        "        )\n",
        "    return df\n",
        "\n",
        "\n",
        "def logtransform_num(df):\n",
        "    \"\"\"Perform Log Transformations.\"\"\"\n",
        "    # Pre-processing for the numerical attributes\n",
        "    # 2. Taking the log of the numerical attributes\n",
        "    num_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "    for col in num_cols:\n",
        "        df[\"log_\" + col] = np.log(df[col])\n",
        "        # Doing the following for values 0 and very large values to avoid negative infs\n",
        "        df[\"log_\" + col] = (\n",
        "            df[\"log_\" + col]\n",
        "            .replace(-np.inf, np.mean(df[\"log_\" + col]) - 3 * np.std(df[\"log_\" + col]))\n",
        "            .copy()\n",
        "        )\n",
        "        df[\"log_\" + col] = (\n",
        "            df[\"log_\" + col]\n",
        "            .replace(np.nan, np.mean(df[\"log_\" + col]) + 3 * np.std(df[\"log_\" + col]))\n",
        "            .copy()\n",
        "        )\n",
        "    return df\n",
        "\n",
        "\n",
        "def convert_cat_to_num(df):\n",
        "    \"\"\"Convert Antivirus Features back to numeric.\"\"\"\n",
        "    # Attributes which were tagged as categorical but are numeric\n",
        "    convert_to_num = [\"AVProductsInstalled\", \"AVProductsEnabled\"]\n",
        "\n",
        "    for col in convert_to_num:\n",
        "        df[col] = df[col].astype(float).astype(int).copy()\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# df.drop(columns = corr_cols_drop, inplace = True)\n",
        "# df.drop(columns= cats_to_drop, inplace=True)\n",
        "\n",
        "\n",
        "def treat_firewall(df):\n",
        "    \"\"\"Firewall impute missing Values with 0.\"\"\"\n",
        "    # NA means that firewall was not there\n",
        "    # hence replaced by zero\n",
        "    df[\"Firewall\"].replace(\"-999999999.0\", \"0.0\", inplace=True)\n",
        "    return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBIuN_MwX9NR"
      },
      "outputs": [],
      "source": [
        "def pre_process_df(df1):\n",
        "    \"\"\"Develop a preprocessing pipeline; Step 1.\"\"\"\n",
        "    print(\"[Starting pre-processing.]\")\n",
        "    print(\"Input dataframe has shape {}\".format(df1.shape))\n",
        "\n",
        "    df = df1.copy()\n",
        "    df = replace_nulls(df)\n",
        "    drop_cols(df, cols_to_drop)\n",
        "    df = convert_num_to_cat(df)\n",
        "    df = median_impute(df)\n",
        "    df = treat_outlier(df)\n",
        "    df = logtransform_num(df)\n",
        "    df = convert_cat_to_num(df)\n",
        "    drop_cols(df, corr_cols_drop, cats_to_drop, log_corr_cols_to_drop)\n",
        "    treat_firewall(df)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMwCXTVPYEoA"
      },
      "outputs": [],
      "source": [
        "class preprocessing_freq_encode:\n",
        "    \"\"\"Class will keep the most common occuring features\n",
        "    based on the limit given.\"\"\"\n",
        "\n",
        "    def __init__(self, limit):\n",
        "        \"\"\"Iniatialize Class.\"\"\"\n",
        "        self.limit = limit\n",
        "        self.dict = {}\n",
        "        self.convert_num = []\n",
        "\n",
        "    def fit(self, data_frame):\n",
        "        \"\"\"Perform preprocessing steps and Feature Encoding.\"\"\"\n",
        "        main_df = pre_process_df(data_frame)\n",
        "        for i in list(main_df.select_dtypes(include=\"object\").columns):\n",
        "            if len(main_df[i].unique()) <= 2:\n",
        "                self.convert_num.append(i)\n",
        "            else:\n",
        "                bool_ = main_df[i].value_counts(ascending=False) > self.limit\n",
        "                vals = main_df[i].value_counts(ascending=False)[bool_]\n",
        "                self.dict[i] = list(vals.index)\n",
        "\n",
        "    def transform(self, data_frame):\n",
        "        \"\"\"Transform the Data prior Modelling.\"\"\"\n",
        "        main_df = pre_process_df(data_frame)\n",
        "        data_frame1 = main_df.copy()\n",
        "        for i in self.convert_num:\n",
        "            data_frame1[i] = data_frame1[i].astype('float')\n",
        "        for j in self.dict:\n",
        "            for k in self.dict[j]:\n",
        "                data_frame1[j + k] = np.where(data_frame1[j] == k, 1, 0)\n",
        "        data_frame1.drop(columns=list(self.dict.keys()), inplace=True)\n",
        "        data_frame_final = data_frame1[shortlisted_features].copy()\n",
        "        return data_frame_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMsqc6MiYL0s",
        "outputId": "920aa447-c681-48ff-cbdb-4bda8ef1c74f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Starting pre-processing.]\n",
            "Input dataframe has shape (849325, 76)\n",
            "[Starting pre-processing.]\n",
            "Input dataframe has shape (849325, 76)\n",
            "[Starting pre-processing.]\n",
            "Input dataframe has shape (212332, 76)\n"
          ]
        }
      ],
      "source": [
        "y_train = train[\"HasDetections\"].copy()\n",
        "X_train = train.drop(columns=\"HasDetections\")\n",
        "\n",
        "y_val = val[\"HasDetections\"].copy()\n",
        "X_val = val.drop(columns=\"HasDetections\")\n",
        "\n",
        "model_preprocessing = preprocessing_freq_encode(10_000)\n",
        "model_preprocessing.fit(X_train)\n",
        "train_data = model_preprocessing.transform(X_train)\n",
        "val_data = model_preprocessing.transform(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp3GQHnWsQ7J"
      },
      "outputs": [],
      "source": [
        "train_data = np.array(train_data)\n",
        "y_train = np.array(y_train)\n",
        "val_data = np.array(val_data)\n",
        "y_val = np.array(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIzV7YxemEMT",
        "outputId": "877e613b-e251-45f6-bc98-002346c88897"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [14:03<00:00, 16.86s/it, best loss: -0.6953444949481875]\n",
            "{'boosting_type': 0, 'colsample_bytree': 2, 'learning_rate': 1.2386456533222754, 'min_child_weight': 5, 'n_estimators': 15, 'num_leaves': 15, 'subsample': 0.5797302497580852}\n"
          ]
        }
      ],
      "source": [
        "def LGBM_AUC(params):\n",
        "\n",
        "    LGBM = lgb.LGBMClassifier(**params, random_state=42, device='gpu', verbose=-1, max_depth=-1, objective=\"binary\")\n",
        "    LGBM.fit(train_data, y_train)\n",
        "    y_pred = LGBM.predict_proba(val_data)[:, 1]\n",
        "    AUC = roc_auc_score(y_val, y_pred)\n",
        "    return -1 * AUC\n",
        "\n",
        "\n",
        "lgb_reg_params = {\n",
        "    \"boosting_type\":    hp.choice(\"boosting_type\", ['gbdt','goss',]),\n",
        "    \"learning_rate\":    hp.loguniform(\"learning_rate\", 1e-5, 2),\n",
        "    \"num_leaves\":        hp.choice(\"num_leaves\", range(10, 300, 2)),\n",
        "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
        "    'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n",
        "    'subsample':        hp.uniform('subsample', 0.3, 0.7),\n",
        "    \"n_estimators\":     hp.choice(\"n_estimators\", range(20, 200, 2))\n",
        "}\n",
        "\n",
        "trials = Trials()\n",
        "LGBM_best = fmin(\n",
        "    fn=LGBM_AUC, space=lgb_reg_params, algo=tpe.suggest, max_evals=50, trials=trials\n",
        ")\n",
        "\n",
        "print(LGBM_best)\n",
        "#{'colsample_bytree': 2, 'learning_rate': 1.004603577028842, 'min_child_weight': 5, 'n_estimators': 57, 'num_leaves': 2, 'subsample': 0.5525456435860483}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "LightBGM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
