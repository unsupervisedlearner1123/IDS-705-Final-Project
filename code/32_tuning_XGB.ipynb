{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK4ffxOUHbnq",
        "outputId": "0d62254a-99a9-428d-9528-37fe673a7f39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "i4uV0xRsIbys"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#from catboost import CatBoostClassifier\n",
        "import os\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "from hyperopt import Trials, fmin, tpe, hp\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import loguniform\n",
        "import lightgbm as lgb\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "os.chdir(\"/add/your/path/here/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Mlzq3MUOIoSk"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# Loading shortlisted feature from pickle file\n",
        "with open(\"./trained_models/imp_features.pkl\", \"rb\") as f:\n",
        "  features = pickle.load(f)\n",
        "\n",
        "shortlisted_features = list(features.keys())[:150]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5Z-ETYYwJHcd"
      },
      "outputs": [],
      "source": [
        "# Loading train, test and validation files\n",
        "train = pd.read_csv(\"./data/train.csv\")\n",
        "train.name = \"Train\"\n",
        "val = pd.read_csv(\"./data/val.csv\")\n",
        "val.name = \"Validation\"\n",
        "#test = pd.read_csv(\"./data/test.csv\")\n",
        "#test.name = \"Test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2pAzuX4LJQxr"
      },
      "outputs": [],
      "source": [
        "\n",
        "cols_to_drop = [\n",
        "    \"IsBeta\",\n",
        "    \"AutoSampleOptIn\",\n",
        "    \"SMode\",\n",
        "    \"Census_IsPortableOperatingSystem\",\n",
        "    \"OrganizationIdentifier\",\n",
        "    \"Census_InternalBatteryNumberOfCharges\",\n",
        "]\n",
        "\n",
        "\n",
        "categorical_cols = [\n",
        "    \"IsSxsPassiveMode\",\n",
        "    \"RtpStateBitfield\",\n",
        "    \"AVProductStatesIdentifier\",\n",
        "    \"AVProductsInstalled\",\n",
        "    \"AVProductsEnabled\",\n",
        "    \"HasTpm\",  # think of dropping it\n",
        "    \"CountryIdentifier\",\n",
        "    \"CityIdentifier\",\n",
        "    # \"OrganizationIdentifier\",\n",
        "    \"GeoNameIdentifier\",\n",
        "    \"LocaleEnglishNameIdentifier\",\n",
        "    \"Platform\",\n",
        "    \"Processor\",\n",
        "    \"OsVer\",  # Think of dropping it\n",
        "    \"OsBuild\",\n",
        "    \"OsSuite\",\n",
        "    \"IsProtected\",\n",
        "    \"IeVerIdentifier\",\n",
        "    \"Firewall\",\n",
        "    \"UacLuaenable\",  # THINK of dropping\n",
        "    \"Census_OEMNameIdentifier\",\n",
        "    \"Census_OEMModelIdentifier\",\n",
        "    \"Census_ProcessorManufacturerIdentifier\",\n",
        "    \"Census_ProcessorModelIdentifier\",\n",
        "    \"Census_HasOpticalDiskDrive\",\n",
        "    \"Census_PowerPlatformRoleName\",\n",
        "    \"Census_OSVersion\",\n",
        "    \"Census_OSArchitecture\",\n",
        "    \"Census_OSBranch\",  # OS version\n",
        "    \"Census_OSBuildNumber\",  # OS version\n",
        "    \"Census_OSBuildRevision\",  # OS version\n",
        "    \"Census_OSInstallLanguageIdentifier\",  # think of dropping it\n",
        "    \"Census_OSUILocaleIdentifier\",\n",
        "    \"Census_IsFlightsDisabled\",\n",
        "    \"Census_FlightRing\",\n",
        "    \"Census_FirmwareManufacturerIdentifier\",\n",
        "    \"Census_FirmwareVersionIdentifier\",\n",
        "    \"Census_IsSecureBootEnabled\",\n",
        "    \"Census_IsVirtualDevice\",\n",
        "    \"Census_IsTouchEnabled\",\n",
        "    \"Census_IsPenCapable\",\n",
        "    \"Census_IsAlwaysOnAlwaysConnectedCapable\",\n",
        "    \"Wdft_IsGamer\",\n",
        "    \"Wdft_RegionIdentifier\",\n",
        "    # \"HasDetections\",\n",
        "]\n",
        "\n",
        "nulls_cols = [\n",
        "    \"MachineIdentifier\",\n",
        "    \"ProductName\",\n",
        "    \"EngineVersion\",\n",
        "    \"AppVersion\",\n",
        "    \"AvSigVersion\",\n",
        "    \"IsBeta\",\n",
        "    \"RtpStateBitfield\",\n",
        "    \"IsSxsPassiveMode\",\n",
        "    \"AVProductStatesIdentifier\",\n",
        "    \"AVProductsInstalled\",\n",
        "    \"AVProductsEnabled\",\n",
        "    \"HasTpm\",\n",
        "    \"CountryIdentifier\",\n",
        "    \"CityIdentifier\",\n",
        "    \"OrganizationIdentifier\",\n",
        "    \"GeoNameIdentifier\",\n",
        "    \"LocaleEnglishNameIdentifier\",\n",
        "    \"Platform\",\n",
        "    \"Processor\",\n",
        "    \"OsVer\",\n",
        "    \"OsBuild\",\n",
        "    \"OsSuite\",\n",
        "    \"OsPlatformSubRelease\",\n",
        "    \"OsBuildLab\",\n",
        "    \"SkuEdition\",\n",
        "    \"IsProtected\",\n",
        "    \"AutoSampleOptIn\",\n",
        "    \"SMode\",\n",
        "    \"IeVerIdentifier\",\n",
        "    \"SmartScreen\",\n",
        "    \"Firewall\",\n",
        "    \"UacLuaenable\",\n",
        "    \"Census_MDC2FormFactor\",\n",
        "    \"Census_DeviceFamily\",\n",
        "    \"Census_OEMNameIdentifier\",\n",
        "    \"Census_OEMModelIdentifier\",\n",
        "    \"Census_ProcessorCoreCount\",\n",
        "    \"Census_ProcessorManufacturerIdentifier\",\n",
        "    \"Census_ProcessorModelIdentifier\",\n",
        "    \"Census_PrimaryDiskTotalCapacity\",\n",
        "    \"Census_PrimaryDiskTypeName\",\n",
        "    \"Census_SystemVolumeTotalCapacity\",\n",
        "    \"Census_HasOpticalDiskDrive\",\n",
        "    \"Census_TotalPhysicalRAM\",\n",
        "    \"Census_ChassisTypeName\",\n",
        "    \"Census_InternalPrimaryDiagonalDisplaySizeInInches\",\n",
        "    \"Census_InternalPrimaryDisplayResolutionHorizontal\",\n",
        "    \"Census_InternalPrimaryDisplayResolutionVertical\",\n",
        "    \"Census_PowerPlatformRoleName\",\n",
        "    \"Census_InternalBatteryNumberOfCharges\",\n",
        "    \"Census_OSVersion\",\n",
        "    \"Census_OSArchitecture\",\n",
        "    \"Census_OSBranch\",\n",
        "    \"Census_OSBuildNumber\",\n",
        "    \"Census_OSBuildRevision\",\n",
        "    \"Census_OSEdition\",\n",
        "    \"Census_OSSkuName\",\n",
        "    \"Census_OSInstallTypeName\",\n",
        "    \"Census_OSInstallLanguageIdentifier\",\n",
        "    \"Census_OSUILocaleIdentifier\",\n",
        "    \"Census_OSWUAutoUpdateOptionsName\",\n",
        "    \"Census_IsPortableOperatingSystem\",\n",
        "    \"Census_GenuineStateName\",\n",
        "    \"Census_ActivationChannel\",\n",
        "    \"Census_IsFlightsDisabled\",\n",
        "    \"Census_FlightRing\",\n",
        "    \"Census_FirmwareManufacturerIdentifier\",\n",
        "    \"Census_FirmwareVersionIdentifier\",\n",
        "    \"Census_IsSecureBootEnabled\",\n",
        "    \"Census_IsVirtualDevice\",\n",
        "    \"Census_IsTouchEnabled\",\n",
        "    \"Census_IsPenCapable\",\n",
        "    \"Census_IsAlwaysOnAlwaysConnectedCapable\",\n",
        "    \"Wdft_IsGamer\",\n",
        "    \"Wdft_RegionIdentifier\",\n",
        "    # \"HasDetections\",\n",
        "]\n",
        "\n",
        "# Features to drop post correlation checks\n",
        "corr_cols_drop = [\n",
        "    \"Census_ProcessorCoreCount\",\n",
        "    \"Census_PrimaryDiskTotalCapacity\",\n",
        "    \"Census_SystemVolumeTotalCapacity\",\n",
        "    \"Census_TotalPhysicalRAM\",\n",
        "    \"Census_InternalPrimaryDiagonalDisplaySizeInInches\",\n",
        "    \"Census_InternalPrimaryDisplayResolutionHorizontal\",\n",
        "    \"Census_InternalPrimaryDisplayResolutionVertical\",\n",
        "    \"AVProductsInstalled\",\n",
        "]\n",
        "\n",
        "log_corr_cols_to_drop = [\n",
        "    \"log_Census_PrimaryDiskTotalCapacity\",\n",
        "    \"log_Census_InternalPrimaryDisplayResolutionVertical\",\n",
        "]\n",
        "\n",
        "# Categorical columns similar to other columns\n",
        "# redundant information. Hence dropped.\n",
        "cats_to_drop = [\n",
        "    \"MachineIdentifier\",\n",
        "    \"OsBuildLab\",\n",
        "    \"CityIdentifier\",\n",
        "    \"GeoNameIdentifier\",\n",
        "    \"LocaleEnglishNameIdentifier\",\n",
        "    \"Census_ChassisTypeName\",\n",
        "    \"Census_OSVersion\",\n",
        "    \"Census_OSBranch\",\n",
        "    \"Census_OSBuildNumber\",\n",
        "    \"Census_OSSkuName\",\n",
        "    \"Wdft_RegionIdentifier\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HzCv8ZZBJbHV"
      },
      "outputs": [],
      "source": [
        "def drop_cols(df, *args):\n",
        "    \"\"\"Drop Columns.\"\"\"\n",
        "    for x in args:\n",
        "        df.drop(columns=x, inplace=True)\n",
        "\n",
        "\n",
        "def replace_nulls(df):\n",
        "    \"\"\"Impute Missing Values with Place holders.\"\"\"\n",
        "    # Replace nulls acc to data types\n",
        "    for col in nulls_cols:\n",
        "        if df[col].dtype.name in [\"int64\", \"float64\"]:\n",
        "            df[col] = df[col].fillna(-999999999).copy()\n",
        "        else:\n",
        "            df[col].fillna(\"Missing\", inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "# df.drop(columns = cols_to_drop,inplace=True)\n",
        "\n",
        "\n",
        "def convert_num_to_cat(df):\n",
        "    \"\"\"Ensure Correct Datatypes.\"\"\"\n",
        "    # Correcting some numerical attributes to categorical\n",
        "    for col in categorical_cols:\n",
        "        df[col] = df[col].astype(\"str\").copy()\n",
        "    return df\n",
        "\n",
        "\n",
        "def median_impute(df):\n",
        "    \"\"\"Impute Missing Values with Median.\"\"\"\n",
        "    # Imputing the float attributes with the median\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype.name in [\"int64\", \"float64\"]:\n",
        "            df[col].replace(-999999999, df[col].median(), inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "def treat_outlier(df):\n",
        "    \"\"\"Outlier Treatment by placing them within 3 standard deviations of the mean.\"\"\"\n",
        "    # Pre-processing for the numerical attributes\n",
        "    # 1. Remove the outliers based on 3 standard deviations away from mean\n",
        "    for col in df.select_dtypes(include=np.number).columns.tolist():\n",
        "\n",
        "        a = np.mean(df[col])\n",
        "        b = np.std(df[col])\n",
        "\n",
        "        df[col] = np.where(\n",
        "            df[col] > a + 3 * b,\n",
        "            a + 3 * b,\n",
        "            np.where(df[col] < a - 3 * b, a - 3 * b, df[col]),\n",
        "        )\n",
        "    return df\n",
        "\n",
        "\n",
        "def logtransform_num(df):\n",
        "    \"\"\"Perform Log Transformations.\"\"\"\n",
        "    # Pre-processing for the numerical attributes\n",
        "    # 2. Taking the log of the numerical attributes\n",
        "    num_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "    for col in num_cols:\n",
        "        df[\"log_\" + col] = np.log(df[col])\n",
        "        # Doing the following for values 0 and very large values to avoid negative infs\n",
        "        df[\"log_\" + col] = (\n",
        "            df[\"log_\" + col]\n",
        "            .replace(-np.inf, np.mean(df[\"log_\" + col]) - 3 * np.std(df[\"log_\" + col]))\n",
        "            .copy()\n",
        "        )\n",
        "        df[\"log_\" + col] = (\n",
        "            df[\"log_\" + col]\n",
        "            .replace(np.nan, np.mean(df[\"log_\" + col]) + 3 * np.std(df[\"log_\" + col]))\n",
        "            .copy()\n",
        "        )\n",
        "    return df\n",
        "\n",
        "\n",
        "def convert_cat_to_num(df):\n",
        "    \"\"\"Convert Antivirus Features back to numeric.\"\"\"\n",
        "    # Attributes which were tagged as categorical but are numeric\n",
        "    convert_to_num = [\"AVProductsInstalled\", \"AVProductsEnabled\"]\n",
        "\n",
        "    for col in convert_to_num:\n",
        "        df[col] = df[col].astype(float).astype(int).copy()\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# df.drop(columns = corr_cols_drop, inplace = True)\n",
        "# df.drop(columns= cats_to_drop, inplace=True)\n",
        "\n",
        "\n",
        "def treat_firewall(df):\n",
        "    \"\"\"Firewall impute missing Values with 0.\"\"\"\n",
        "    # NA means that firewall was not there\n",
        "    # hence replaced by zero\n",
        "    df[\"Firewall\"].replace(\"-999999999.0\", \"0.0\", inplace=True)\n",
        "    return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-39KhX7PJe7h"
      },
      "outputs": [],
      "source": [
        "def pre_process_df(df1):\n",
        "    \"\"\"Develop a preprocessing pipeline; Step 1.\"\"\"\n",
        "    print(\"[Starting pre-processing.]\")\n",
        "    print(\"Input dataframe has shape {}\".format(df1.shape))\n",
        "\n",
        "    df = df1.copy()\n",
        "    df = replace_nulls(df)\n",
        "    drop_cols(df, cols_to_drop)\n",
        "    df = convert_num_to_cat(df)\n",
        "    df = median_impute(df)\n",
        "    df = treat_outlier(df)\n",
        "    df = logtransform_num(df)\n",
        "    df = convert_cat_to_num(df)\n",
        "    drop_cols(df, corr_cols_drop, cats_to_drop, log_corr_cols_to_drop)\n",
        "    treat_firewall(df)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hAGLSakbJhcS"
      },
      "outputs": [],
      "source": [
        "class preprocessing_freq_encode:\n",
        "    \"\"\"Class will keep the most common occuring features\n",
        "    based on the limit given.\"\"\"\n",
        "\n",
        "    def __init__(self, limit):\n",
        "        \"\"\"Iniatialize Class.\"\"\"\n",
        "        self.limit = limit\n",
        "        self.dict = {}\n",
        "        self.convert_num = []\n",
        "\n",
        "    def fit(self, data_frame):\n",
        "        \"\"\"Perform preprocessing steps and Feature Encoding.\"\"\"\n",
        "        main_df = pre_process_df(data_frame)\n",
        "        for i in list(main_df.select_dtypes(include=\"object\").columns):\n",
        "            if len(main_df[i].unique()) <= 2:\n",
        "                self.convert_num.append(i)\n",
        "            else:\n",
        "                bool_ = main_df[i].value_counts(ascending=False) > self.limit\n",
        "                vals = main_df[i].value_counts(ascending=False)[bool_]\n",
        "                self.dict[i] = list(vals.index)\n",
        "\n",
        "    def transform(self, data_frame):\n",
        "        \"\"\"Transform the Data prior Modelling.\"\"\"\n",
        "        main_df = pre_process_df(data_frame)\n",
        "        data_frame1 = main_df.copy()\n",
        "        for i in self.convert_num:\n",
        "            data_frame1[i] = data_frame1[i].astype('float')\n",
        "        for j in self.dict:\n",
        "            for k in self.dict[j]:\n",
        "                data_frame1[j + k] = np.where(data_frame1[j] == k, 1, 0)\n",
        "        data_frame1.drop(columns=list(self.dict.keys()), inplace=True)\n",
        "        data_frame_final = data_frame1[shortlisted_features].copy()\n",
        "        return data_frame_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "g4DTaqCXJkb7"
      },
      "outputs": [],
      "source": [
        "y_train = train[\"HasDetections\"].copy()\n",
        "X_train = train.drop(columns=\"HasDetections\")\n",
        "\n",
        "y_val = val[\"HasDetections\"].copy()\n",
        "X_val = val.drop(columns=\"HasDetections\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db2qxFo0Jm8-",
        "outputId": "571b7985-80ce-40e2-b7cc-b1b033147829"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Starting pre-processing.]\n",
            "Input dataframe has shape (849325, 76)\n",
            "[Starting pre-processing.]\n",
            "Input dataframe has shape (849325, 76)\n",
            "[Starting pre-processing.]\n",
            "Input dataframe has shape (212332, 76)\n"
          ]
        }
      ],
      "source": [
        "model_preprocessing = preprocessing_freq_encode(10_000)\n",
        "model_preprocessing.fit(X_train)\n",
        "train_data = model_preprocessing.transform(X_train)\n",
        "val_data = model_preprocessing.transform(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XPg22mJQJ6MS"
      },
      "outputs": [],
      "source": [
        "train_data = np.array(train_data)\n",
        "val_data = np.array(val_data)\n",
        "y_train = np.array(y_train)\n",
        "y_val = np.array(y_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IckI7vVxJosy",
        "outputId": "1c4258c3-daf2-4839-966c-5805d4eb3925"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [06:23<00:00, 38.32s/it, best loss: -0.7013297110726283]\n",
            "{'colsample_bytree': 0.23, 'gamma': 0.16, 'learning_rate': 0.06, 'max_depth': 9, 'min_child_weight': 9.0, 'n_estimators': 19, 'subsample': 0.14}\n"
          ]
        }
      ],
      "source": [
        "def XGB_AUC(params):\n",
        "\n",
        "    XGB = XGBClassifier(\n",
        "        **params, random_state=42, silent=True, verbosity=0, tree_method='gpu_hist'\n",
        "    )\n",
        "    XGB.fit(train_data, y_train)\n",
        "    y_pred = XGB.predict_proba(val_data)[:, 1]\n",
        "    AUC = roc_auc_score(y_val, y_pred)\n",
        "    return -1 * AUC\n",
        "\n",
        "\n",
        "XGB_Space = space = {\n",
        "    \"max_depth\": hp.choice(\"max_depth\", range(5, 30, 1)),\n",
        "    \"learning_rate\": hp.quniform(\"learning_rate\", 0.001, 1, 0.01),\n",
        "    \"n_estimators\": hp.choice(\"n_estimators\", range(20, 150, 5)),\n",
        "    \"gamma\": hp.quniform(\"gamma\", 0, 0.50, 0.01),\n",
        "    \"min_child_weight\": hp.quniform(\"min_child_weight\", 1, 10, 1),\n",
        "    \"subsample\": hp.quniform(\"subsample\", 0.1, 0.7, 0.01),\n",
        "    \"colsample_bytree\": hp.quniform(\"colsample_bytree\", 0.1, 0.8, 0.01),\n",
        "}\n",
        "\n",
        "trials = Trials()\n",
        "best = fmin(fn=XGB_AUC, space=XGB_Space, algo=tpe.suggest, max_evals=10, trials=trials)\n",
        "\n",
        "print(best)\n",
        "#{'colsample_bytree': 0.23, 'gamma': 0.16, 'learning_rate': 0.06, 'max_depth': 9, 'min_child_weight': 9.0, 'n_estimators': 19, 'subsample': 0.14}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "XGBoost.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
